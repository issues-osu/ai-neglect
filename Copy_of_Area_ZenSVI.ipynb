{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "mount_file_id": "1c5j-Blnpj1zuuaBf-o0sa5Up6gA-PH4m",
      "authorship_tag": "ABX9TyNivdM3dFNhRDJpeCxB2riJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvWvXQst-hT7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/koito19960406/ZenSVI.git"
      ],
      "metadata": {
        "id": "wGSQERvH_BqE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "sAwbAAs__COB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API key and paths\n",
        "mly_api_key = \"XXXX""
      ],
      "metadata": {
        "id": "HTD5VXAb_Gwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from zensvi.download import MLYDownloader\n",
        "\n",
        "# Path to your shapefile\n",
        "input_shp_file = \"/content/drive/MyDrive/area.geojson\"\n",
        "\n",
        "# Output folder\n",
        "output_folder = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Initialize downloader\n",
        "downloader = MLYDownloader(mly_api_key)\n",
        "\n",
        "# Download images using the shapefile\n",
        "downloader.download_svi(\n",
        "    dir_output=output_folder,\n",
        "    input_shp_file=input_shp_file,\n",
        "    buffer=800  # meters around the polygon/points\n",
        ")"
      ],
      "metadata": {
        "id": "T3EYUdvzLC1A",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg_base = \"/content/drive/MyDrive/zensvi_outputs/segmentation_fixed\"\n",
        "seg_dir = os.path.join(seg_base, \"segments\")\n",
        "sum_dir = os.path.join(seg_base, \"summaries\")\n",
        "\n",
        "os.makedirs(seg_dir, exist_ok=True)\n",
        "os.makedirs(sum_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "1K9B0oJT2fX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zensvi.cv import Segmenter\n",
        "import glob, os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "segmenter = Segmenter()\n",
        "\n",
        "# Get all .pngs in all batch folders\n",
        "img_paths = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/batch_*/**/*.png\", recursive=True)\n",
        "\n",
        "print(f\"üì¶ Total images found: {len(img_paths)}\")\n",
        "\n",
        "seg_base = \"/content/drive/MyDrive/zensvi_outputs/segmentation_clean\"\n",
        "seg_dir = os.path.join(seg_base, \"segments\")\n",
        "os.makedirs(seg_dir, exist_ok=True)\n",
        "\n",
        "processed = 0\n",
        "skipped = 0\n",
        "failed = 0\n",
        "\n",
        "for img_path in img_paths:\n",
        "    filename = Path(img_path).stem\n",
        "\n",
        "    # Per-image summary folder\n",
        "    summary_dir = os.path.join(seg_base, \"summaries\", filename)\n",
        "    os.makedirs(summary_dir, exist_ok=True)\n",
        "\n",
        "    out_img = os.path.join(seg_dir, f\"{filename}_colored_segmented.png\")\n",
        "    summary_csv = os.path.join(summary_dir, \"pixel_ratios.csv\")\n",
        "\n",
        "    # Skip if already processed\n",
        "    if os.path.exists(out_img) and os.path.exists(summary_csv):\n",
        "        print(f\"‚è≠Ô∏è Already segmented: {filename}\")\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    # ‚úÖ Check if image is corrupt\n",
        "    try:\n",
        "        with Image.open(img_path) as img:\n",
        "            img.verify()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Skipping invalid image {filename}: {e}\")\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    # üß† Segment safely\n",
        "    try:\n",
        "        segmenter.segment(img_path, seg_dir, summary_dir)\n",
        "        print(f\"‚úÖ Segmented: {filename}\")\n",
        "        processed += 1\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Segmentation failed for {filename}: {e}\")\n",
        "        failed += 1\n",
        "\n",
        "print(\"\\nüìä Summary\")\n",
        "print(f\"‚úÖ Processed: {processed}\")\n",
        "print(f\"‚è≠Ô∏è Skipped (already exists or invalid): {skipped}\")\n",
        "print(f\"‚ùå Failed: {failed}\")\n"
      ],
      "metadata": {
        "id": "0fvZgd0D3IqD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set path\n",
        "summary_base = \"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\"\n",
        "\n",
        "# Count all folders and CSVs inside\n",
        "folder_count = 0\n",
        "csv_count = 0\n",
        "\n",
        "for root, dirs, files in os.walk(summary_base):\n",
        "    if root == summary_base:\n",
        "        folder_count += len(dirs)\n",
        "    csv_count += sum(1 for file in files if file.endswith('.csv'))\n",
        "\n",
        "print(f\"üìÅ Total summary folders: {folder_count}\")\n",
        "print(f\"üìÑ Total pixel_ratios.csv files: {csv_count}\")\n"
      ],
      "metadata": {
        "id": "5AVz_g1RpHXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "summary_root = \"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\"\n",
        "\n",
        "# List the first few subfolders (these should be per image ID)\n",
        "folders = os.listdir(summary_root)\n",
        "print(\"üîç Example summary folders:\", folders[:5])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rwjLkPLVcvnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "summary_root = \"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\"\n",
        "test_folder = os.path.join(summary_root, \"173207791418255\")  # or pick any from your list\n",
        "csv_path = os.path.join(test_folder, \"pixel_ratios.csv\")\n",
        "\n",
        "# Test loading\n",
        "print(f\"üîç Trying to load: {csv_path}\")\n",
        "try:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(\"‚úÖ Read successful! Columns:\", df.columns.tolist())\n",
        "    print(df.head())\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to read CSV: {e}\")\n"
      ],
      "metadata": {
        "id": "CAtT0g4OprYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set the root directory for summaries\n",
        "summary_root = Path(\"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\")\n",
        "\n",
        "# Use tqdm to track progress as you search for pixel_ratios.csv\n",
        "csv_files = []\n",
        "for p in tqdm(summary_root.iterdir(), total=27701):  # or remove total=27701 if unsure of total count\n",
        "    path = p / \"pixel_ratios.csv\"\n",
        "    if path.exists():\n",
        "        csv_files.append(path)\n",
        "\n",
        "print(f\"üì¶ Total pixel_ratios.csv files found: {len(csv_files)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "F9uG1xdTpy3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "all_dfs = []\n",
        "total_files = len(csv_files)\n",
        "\n",
        "for i, file_path in enumerate(csv_files, start=1):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        image_id = file_path.parent.name\n",
        "        df[\"image_id\"] = image_id\n",
        "        all_dfs.append(df)\n",
        "        print(f\"‚úÖ [{i}/{total_files}] Loaded: {image_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå [{i}/{total_files}] Failed reading {file_path}: {e}\")\n",
        "\n",
        "df_all = pd.concat(all_dfs, ignore_index=True)\n",
        "df_pivot = df_all.pivot(index=\"image_id\", columns=\"label_name\", values=\"pixel_ratios\").reset_index()\n",
        "df_pivot.to_csv(\"/content/drive/MyDrive/zensvi_outputs/test_pixel_ratios_pivot.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ Done! Pivoted shape:\", df_pivot.shape)\n",
        "print(\"üìÅ Saved pivoted data to: test_pixel_ratios_pivot.csv\")\n"
      ],
      "metadata": {
        "id": "NBWsOH4Vqj4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the pivoted pixel ratio values\n",
        "df_pixel = pd.read_csv(\"/content/drive/MyDrive/zensvi_outputs/test_pixel_ratios_pivot.csv\")\n",
        "\n",
        "# Load the PID file with lat/lon (adjust filename if needed)\n",
        "df_pid = pd.read_csv(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids.csv\")\n",
        "\n",
        "# Merge vegetation with coordinates\n",
        "df_plot = df_pixel.merge(df_pid, left_on=\"image_id\", right_on=\"id\")\n",
        "\n",
        "print(\"‚úÖ Merged shape:\", df_plot.shape)\n",
        "print(df_plot[[\"image_id\", \"lat\", \"lon\", \"vegetation\"]].head())\n"
      ],
      "metadata": {
        "id": "laSe8buNfO_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Create GeoDataFrame\n",
        "gdf = gpd.GeoDataFrame(\n",
        "    df_plot,\n",
        "    geometry=[Point(xy) for xy in zip(df_plot[\"lon\"], df_plot[\"lat\"])],\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# Plot vegetation values\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "gdf.plot(\n",
        "    column=\"vegetation\",\n",
        "    cmap=\"YlGn\",\n",
        "    markersize=5,\n",
        "    alpha=0.7,\n",
        "    legend=True,\n",
        "    ax=ax\n",
        ")\n",
        "ax.set_title(\"Street-Level Vegetation Scores\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w7UowG0aDj_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the PID file\n",
        "pid_path = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids.csv\"\n",
        "df_pid = pd.read_csv(pid_path)\n",
        "\n",
        "# Check the current column names\n",
        "print(df_pid.columns)\n",
        "\n",
        "df_pid = df_pid.rename(columns={\"id\": \"panoid\"})\n",
        "df_pid.to_csv(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\", index=False)\n",
        "print(\"‚úÖ Renamed and saved to mly_pids_renamed.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "dneWIyqvS6lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "sample_path = Path(\"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\")\n",
        "first_csv = list(sample_path.rglob(\"pixel_ratios.csv\"))[0]\n",
        "df_sample = pd.read_csv(first_csv)\n",
        "\n",
        "print(\"‚úÖ Columns in sample file:\", df_sample[\"label_name\"].unique())\n"
      ],
      "metadata": {
        "id": "cfi-wBkqT918"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "summary_root = Path(\"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\")\n",
        "csv_files = list(summary_root.glob(\"*/pixel_ratios.csv\"))\n",
        "\n",
        "for file_path in tqdm(csv_files):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df_wide = df.pivot(index='filename_key', columns='label_name', values='pixel_ratios').reset_index()\n",
        "        output_path = file_path.parent / \"pixel_ratios_wide.csv\"\n",
        "        df_wide.to_csv(output_path, index=False)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed: {file_path} ‚Äî {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "5J_3ka4DUzRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Set paths\n",
        "summary_root = Path(\"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\")\n",
        "pid_path = Path(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\")\n",
        "output_csv = \"/content/drive/MyDrive/zensvi_outputs/zensvi_qgis_ready.csv\"\n",
        "\n",
        "# 2. Get wide pixel ratio files\n",
        "wide_csv_files = list(summary_root.glob(\"*/pixel_ratios_wide.csv\"))\n",
        "\n",
        "# 3. Read all wide files and append image_id\n",
        "all_dfs = []\n",
        "for file_path in tqdm(wide_csv_files):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        image_id = file_path.parent.name\n",
        "        df[\"image_id\"] = image_id\n",
        "        all_dfs.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed on {file_path}: {e}\")\n",
        "\n",
        "df_pixel = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "# 4. Read PID file and rename column to match\n",
        "df_pids = pd.read_csv(pid_path)\n",
        "df_pids = df_pids.rename(columns={\"id\": \"image_id\"})\n"
      ],
      "metadata": {
        "id": "_UW9zYWbXIN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Load the PIDs file\n",
        "path_pid = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\"\n",
        "df_pids = pd.read_csv(path_pid)\n",
        "\n",
        "# 2. Check current column names\n",
        "print(\"üß† PID columns:\", df_pids.columns.tolist())\n",
        "\n",
        "# 3. Rename 'id' to 'image_id' only if it exists\n",
        "if 'id' in df_pids.columns:\n",
        "    df_pids = df_pids.rename(columns={'id': 'image_id'})\n",
        "\n",
        "# 4. Confirm rename worked\n",
        "print(\"‚úÖ Renamed columns:\", df_pids.columns.tolist())\n"
      ],
      "metadata": {
        "id": "vA3kAbgJYEzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the combined wide pixel ratio data\n",
        "df_pixel = pd.read_csv(\"/content/drive/MyDrive/zensvi_outputs/test_pixel_ratios_pivot.csv\")\n",
        "df_pixel.rename(columns={\"image_id\": \"panoid\"}, inplace=True)\n"
      ],
      "metadata": {
        "id": "-DErLSn5ZwC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pids\n",
        "df_pids = pd.read_csv(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\")\n",
        "\n",
        "# Confirm the key columns exist\n",
        "assert \"panoid\" in df_pids.columns and \"lat\" in df_pids.columns and \"lon\" in df_pids.columns\n"
      ],
      "metadata": {
        "id": "9WtYAHr1ZzWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Load the wide-format pixel ratios\n",
        "df_pixel = pd.read_csv(\"/content/drive/MyDrive/zensvi_outputs/test_pixel_ratios_pivot.csv\")\n",
        "\n",
        "# 2. Load the pids with coordinates\n",
        "df_pids = pd.read_csv(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\")\n",
        "\n",
        "# 3. Make sure both use the same column name for merging\n",
        "df_pixel.rename(columns={\"image_id\": \"panoid\"}, inplace=True)\n",
        "\n",
        "# 4. Merge on panoid\n",
        "df_merged = pd.merge(df_pixel, df_pids[[\"panoid\", \"lat\", \"lon\"]], on=\"panoid\", how=\"inner\")\n",
        "\n",
        "# 5. Save for QGIS\n",
        "output_path = \"/content/drive/MyDrive/zensvi_outputs/pixel_ratios_with_coords.csv\"\n",
        "df_merged.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ File saved for QGIS: {output_path}\")\n",
        "print(f\"üìê Shape: {df_merged.shape}\")\n"
      ],
      "metadata": {
        "id": "CJQN6crJZ1HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Ensure the output directory exists\n",
        "output_dir = \"/content/drive/MyDrive/zensvi_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define output path\n",
        "output_path = os.path.join(output_dir, \"pixel_ratios_with_coords.csv\")\n",
        "\n",
        "# Save the DataFrame\n",
        "df_merged.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ File saved for QGIS: {output_path}\")\n",
        "print(f\"üìê Shape: {df_merged.shape}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tFjQ2rfEYf0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zensvi.visualization import plot_map\n",
        "\n",
        "# ‚úÖ Set correct paths\n",
        "path_pid = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\"\n",
        "dir_input = \"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\"\n",
        "csv_file_pattern = \"pixel_ratios_wide.csv\"  # MUST MATCH THE NEW WIDE FILES\n",
        "path_output = \"/content/drive/MyDrive/zensvi_outputs/vegetation_point_map.png\"\n",
        "\n",
        "# ‚úÖ Generate vegetation point map\n",
        "fig, ax = plot_map(\n",
        "    path_pid=path_pid,\n",
        "    dir_input=dir_input,\n",
        "    csv_file_pattern=csv_file_pattern,\n",
        "    variable_name=\"vegetation\",\n",
        "    plot_type=\"point\",  # use \"point\" for individual image-level values\n",
        "    path_output=path_output,\n",
        "    resolution=13,\n",
        "    cmap=\"YlGn\",\n",
        "    legend=True,\n",
        "    title=\"Vegetation Coverage (Point Map)\",\n",
        "    legend_title=\"Vegetation Ratio\",\n",
        "    dark_mode=False,\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lpuQtlKMeoO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"\n",
        "\n",
        "dir_input = \"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\"\n",
        "path_output = \"/content/drive/MyDrive/zensvi_outputs/vegetation_line_map.png\"\n",
        "path_pid = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\"\n",
        "csv_file_pattern = \"pixel_ratios_wide.csv\"  # pattern of the CSV files that contain the pixel ratios (or any other variable to plot)\n",
        "variable = \"vegetation\"  # variable to plot (e.g. vegetation, building, sky, etc.). This should be the column name in the CSV file. If None, count of the number of images is plotted\n",
        "plot_type = \"line\"  # plot type (either \"point\", \"line\", or \"hexagon\")\n",
        "fig, ax = plot_map(\n",
        "    path_pid,\n",
        "    dir_input=dir_input,\n",
        "    csv_file_pattern=csv_file_pattern,\n",
        "    variable_name=\"vegetation\",\n",
        "    plot_type=plot_type,\n",
        "    path_output=path_output,\n",
        "    resolution=13,\n",
        "    cmap=\"viridis\",\n",
        "    legend=True,\n",
        "    title=\"Point Map\",\n",
        "    legend_title=\"Vegetation\",\n",
        "    dark_mode=False,\n",
        ")\n",
        "ax.set_title(\"Vegetation Map\", fontname=\"DejaVu Sans\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7R_RRqW3ezza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_input = \"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/summaries\"\n",
        "path_output = \"/content/drive/MyDrive/zensvi_outputs/vegetation_hex_map.png\"\n",
        "path_pid = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\"\n",
        "csv_file_pattern = \"pixel_ratios_wide.csv\"  # pattern of the CSV files that contain the pixel ratios (or any other variable to plot)\n",
        "variable = \"vegetation\"  # variable to plot (e.g. vegetation, building, sky, etc.). This should be the column name in the CSV file. If None, count of the number of images is plotted\n",
        "plot_type = \"hexagon\"  # plot type (either \"point\", \"line\", or \"hexagon\")\n",
        "fig, ax = plot_map(\n",
        "    path_pid,\n",
        "    dir_input=dir_input,\n",
        "    csv_file_pattern=csv_file_pattern,\n",
        "    variable_name=variable,\n",
        "    plot_type=plot_type,\n",
        "    path_output=path_output,\n",
        "    resolution=13,\n",
        "    cmap=\"viridis\",\n",
        "    legend=True,\n",
        "    title=\"Point Map\",\n",
        "    legend_title=\"Vegetation\",\n",
        "    dark_mode=False,\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SLKHudbnkJub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create geometry column from lat/lon\n",
        "gdf = gpd.GeoDataFrame(df_merged, geometry=gpd.points_from_xy(df_merged[\"lon\"], df_merged[\"lat\"]))\n",
        "gdf = gdf.set_crs(\"EPSG:4326\")\n",
        "\n",
        "# Plot vegetation ratio\n",
        "gdf.plot(column=\"vegetation\", cmap=\"Greens\", legend=True, figsize=(10, 8))\n",
        "plt.title(\"Street-Level Vegetation from Segmentations\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aLUkdEeNzTMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "summary_files = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/summaries/*.json\", recursive=True)\n",
        "print(f\"üîç Found {len(summary_files)} summary files.\")\n",
        "print(\"Example:\", summary_files[:3])\n",
        "\n"
      ],
      "metadata": {
        "id": "AzDPI1IMxKZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "# Directory containing segmented images\n",
        "seg_dir = Path(\"/content/drive/MyDrive/zensvi_outputs/segmentation_clean/segments\")\n",
        "\n",
        "# Create an iterator of PNG files\n",
        "png_iterator = (p for p in seg_dir.iterdir() if p.suffix == \".png\")\n",
        "\n",
        "# Randomly select 9 from the iterator (reservoir sampling)\n",
        "sample_paths = []\n",
        "for i, path in enumerate(png_iterator, 1):\n",
        "    if len(sample_paths) < 9:\n",
        "        sample_paths.append(path)\n",
        "    else:\n",
        "        j = random.randint(0, i)\n",
        "        if j < 9:\n",
        "            sample_paths[j] = path\n",
        "\n",
        "print(f\"üéØ Sampled {len(sample_paths)} images.\")\n",
        "\n",
        "# Create a 3x3 grid plot\n",
        "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
        "fig.suptitle(\"Segmented Built Environment ‚Äì Sample View\", fontsize=18)\n",
        "\n",
        "# Plot the images\n",
        "for ax, img_path in zip(axes.flatten(), sample_paths):\n",
        "    img = Image.open(img_path)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(img_path.name, fontsize=10)\n",
        "\n",
        "# Hide unused subplots (if fewer than 9)\n",
        "for i in range(len(sample_paths), 9):\n",
        "    axes.flatten()[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.92)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cTeM-9RUxQex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from zensvi.metadata import MLYMetadata\n",
        "\n",
        "# Step 1: Read your renamed file\n",
        "path_input_raw = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\"\n",
        "df = pd.read_csv(path_input_raw)\n",
        "\n",
        "# Step 2: Rename `panoid` ‚Üí `id` to match zensvi's expectation\n",
        "df = df.rename(columns={\"panoid\": \"id\"})\n",
        "\n",
        "# Step 3: Save a temporary corrected file for metadata processing\n",
        "path_input_fixed = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_FOR_METADATA.csv\"\n",
        "df.to_csv(path_input_fixed, index=False)\n",
        "\n",
        "# Step 4: Create output directory\n",
        "output_folder = \"/content/drive/MyDrive/svi_metadata\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Step 5: Run metadata extraction using fixed input\n",
        "mly_metadata = MLYMetadata(path_input=path_input_fixed)\n",
        "\n",
        "# Step 6: Compute and save image-level metadata\n",
        "mly_metadata.compute_metadata(\n",
        "    unit=\"image\",\n",
        "    indicator_list=\"all\",\n",
        "    path_output=os.path.join(output_folder, \"image_metadata.csv\")\n",
        ")\n",
        "\n",
        "# Step 7: Compute and save grid-level metadata\n",
        "mly_metadata.compute_metadata(\n",
        "    unit=\"grid\",\n",
        "    indicator_list=\"all\",\n",
        "    path_output=os.path.join(output_folder, \"grid_metadata.csv\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "wyxfkOAx4Rss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import LineString\n",
        "\n",
        "# Load your image-level metadata (which succeeded)\n",
        "df_image = pd.read_csv(\"/content/drive/MyDrive/svi_metadata/image_metadata.csv\")\n",
        "\n",
        "# Filter out bad or missing values\n",
        "df_image = df_image.dropna(subset=[\"lat\", \"lon\", \"sequence_id\", \"captured_at\"])\n",
        "\n",
        "# Sort by sequence and timestamp\n",
        "df_image = df_image.sort_values([\"sequence_id\", \"captured_at\"])\n",
        "\n",
        "# Convert to GeoDataFrame\n",
        "gdf_image = gpd.GeoDataFrame(\n",
        "    df_image,\n",
        "    geometry=gpd.points_from_xy(df_image.lon, df_image.lat),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# Group by sequence_id and create LineString if >1 point\n",
        "street_records = []\n",
        "for seq_id, group in gdf_image.groupby(\"sequence_id\"):\n",
        "    if len(group) < 2:\n",
        "        continue  # skip sequences that can‚Äôt form a line\n",
        "\n",
        "    line = LineString(group.geometry.tolist())\n",
        "    record = {\n",
        "        \"sequence_id\": seq_id,\n",
        "        \"mean_speed_kmh\": group[\"speed_kmh\"].mean(),\n",
        "        \"mean_angle\": group[\"relative_angle\"].mean(),\n",
        "        \"mean_hour\": group[\"hour\"].mean(),\n",
        "        \"geometry\": line\n",
        "    }\n",
        "    street_records.append(record)\n",
        "\n",
        "# Convert to GeoDataFrame\n",
        "street_gdf = gpd.GeoDataFrame(street_records, crs=\"EPSG:4326\")\n",
        "\n",
        "# Save manually\n",
        "output_path = \"/content/drive/MyDrive/svi_metadata/street_metadata.csv\"\n",
        "street_gdf.drop(columns=\"geometry\").to_csv(output_path, index=False)\n",
        "street_gdf.to_file(output_path.replace(\".csv\", \".geojson\"), driver=\"GeoJSON\")\n",
        "\n",
        "print(f\"‚úÖ Manual street metadata saved to:\\n- CSV: {output_path}\\n- GeoJSON: {output_path.replace('.csv', '.geojson')}\")\n"
      ],
      "metadata": {
        "id": "L70BppE8XBI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.geometry import Polygon, LineString\n",
        "import h3\n",
        "\n",
        "# === Load image and street metadata ===\n",
        "df_image = pd.read_csv(\"/content/drive/MyDrive/svi_metadata/image_metadata.csv\")\n",
        "df_street = pd.read_csv(\"/content/drive/MyDrive/svi_metadata/street_metadata.csv\")\n",
        "\n",
        "# === Convert to GeoDataFrames ===\n",
        "\n",
        "# 1. Image-level: point geometry\n",
        "gdf = gpd.GeoDataFrame(\n",
        "    df_image,\n",
        "    geometry=gpd.points_from_xy(df_image.lon, df_image.lat),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# 2. Street-level: ensure geometry is loaded\n",
        "if 'geometry' not in df_street.columns or not pd.api.types.is_object_dtype(df_street['geometry']):\n",
        "    df_street = gpd.read_file(\"/content/drive/MyDrive/svi_metadata/street_metadata.geojson\")\n",
        "street_gdf = gpd.GeoDataFrame(df_street, geometry='geometry', crs=\"EPSG:4326\")\n",
        "\n",
        "# 3. Grid-level: aggregate image data to h3_9\n",
        "# Compute h3_9 index\n",
        "gdf['h3_9'] = gdf.apply(lambda row: h3.geo_to_h3(row['lat'], row['lon'], 9), axis=1)\n",
        "\n",
        "# Group and compute means\n",
        "df_grid = gdf.groupby('h3_9').agg({\n",
        "    'relative_angle': 'mean',\n",
        "    'speed_kmh': 'mean',\n",
        "    'hour': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Convert h3_9 index to geometry\n",
        "def h3_to_polygon(h):\n",
        "    try:\n",
        "        return Polygon(h3.h3_to_geo_boundary(h, geo_json=True))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "df_grid['geometry'] = df_grid['h3_9'].apply(h3_to_polygon)\n",
        "grid_gdf = gpd.GeoDataFrame(df_grid, geometry='geometry', crs=\"EPSG:4326\").dropna(subset=['geometry'])\n",
        "\n",
        "# === Variables matrix ===\n",
        "var_matrix = [\n",
        "    ['relative_angle', 'average_relative_angle', 'relative_angle'],  # updated for h3_9\n",
        "    ['speed_kmh', 'mean_speed_kmh', 'speed_kmh'],\n",
        "    ['hour', 'mean_hour', 'hour']\n",
        "]\n",
        "\n",
        "row_titles = ['Angle', 'Speed', 'Time']\n",
        "col_titles = ['Unit: image', 'Unit: street', 'Unit: h3_9 grid']\n",
        "gdfs = [gdf, street_gdf, grid_gdf]\n",
        "\n",
        "# === Plot 3x3 matrix ===\n",
        "fig, axes = plt.subplots(3, 3, figsize=(12, 10), dpi=150)\n",
        "\n",
        "for i in range(3):  # rows\n",
        "    for j in range(3):  # columns\n",
        "        ax = axes[i, j]\n",
        "        g = gdfs[j]\n",
        "        var = var_matrix[i][j]\n",
        "\n",
        "        if var in g.columns and not g.empty:\n",
        "            geom_type = g.geometry.iloc[0].geom_type\n",
        "            ms = 2 if geom_type == 'Point' else None\n",
        "            g.plot(column=var, ax=ax, cmap='plasma', legend=True, markersize=ms)\n",
        "        else:\n",
        "            ax.text(0.5, 0.5, f\"{var} missing\", ha='center', va='center', fontsize=12)\n",
        "\n",
        "        ax.set_axis_off()\n",
        "        if i == 0:\n",
        "            ax.set_title(col_titles[j], fontsize=14)\n",
        "        if j == 0:\n",
        "            ax.text(-0.1, 0.5, row_titles[i], va='center', ha='right',\n",
        "                    fontsize=14, transform=ax.transAxes, rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(left=0.05, right=0.95, top=0.95)\n",
        "plt.suptitle(\"Figure: A matrix of maps representing various metadata (with H3_9 grid)\", fontsize=20)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ILfvtJgJ4YAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import h3\n",
        "from shapely.geometry import Polygon\n",
        "\n",
        "# Load your image-level metadata\n",
        "df_meta = pd.read_csv(\"/content/drive/MyDrive/svi_metadata/image_metadata.csv\")\n",
        "\n",
        "# If h3_id is not at resolution 9, compute h3_9 from lat/lon\n",
        "# Otherwise, rename for consistency\n",
        "if 'h3_id' in df_meta.columns:\n",
        "    df_meta['h3_9'] = df_meta['h3_id']\n",
        "else:\n",
        "    df_meta['h3_9'] = df_meta.apply(lambda row: h3.geo_to_h3(row['lat'], row['lon'], 9), axis=1)\n",
        "\n",
        "# Aggregate average speed by h3_9\n",
        "df_agg = df_meta.groupby('h3_9').agg({'speed_kmh': 'mean'}).reset_index()\n",
        "\n",
        "# Convert each h3 index to a hexagon polygon\n",
        "def h3_to_polygon(h):\n",
        "    try:\n",
        "        boundary = h3.h3_to_geo_boundary(h, geo_json=True)\n",
        "        return Polygon(boundary)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "df_agg['geometry'] = df_agg['h3_9'].apply(h3_to_polygon)\n",
        "\n",
        "# Create a GeoDataFrame\n",
        "gdf_hex = gpd.GeoDataFrame(df_agg, geometry='geometry', crs=\"EPSG:4326\").dropna(subset=['geometry'])\n",
        "\n",
        "# Plot hex polygons colored by average speed\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "gdf_hex.plot(column='speed_kmh', cmap='viridis', linewidth=0.5, edgecolor='k', legend=True, ax=ax)\n",
        "ax.set_title('Average Speed (km/h) by H3 Grid (Resolution 9)', fontsize=14)\n",
        "ax.set_axis_off()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5OmkP8Hb9QnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from zensvi.download import MLYDownloader\n",
        "\n",
        "# Your Mapillary API key\n",
        "mly_api_key = \"MLY|7992912717499684|9b96fd3ed8c786f18278269db68375e8\"\n",
        "\n",
        "# Path to your shapefile\n",
        "input_shp_file = \"/content/drive/MyDrive/area.geojson\"\n",
        "\n",
        "# Output folder\n",
        "output_folder = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Initialize downloader\n",
        "downloader = MLYDownloader(mly_api_key)\n",
        "\n",
        "# Download images using the shapefile\n",
        "downloader.download_svi(\n",
        "    dir_output=output_folder,\n",
        "    input_shp_file=input_shp_file,\n",
        "    buffer=800  # meters around the polygon/points\n",
        ")\n"
      ],
      "metadata": {
        "id": "z-VNtMKIOM1c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "# Load image-level CSV\n",
        "df_image = pd.read_csv(\"/content/drive/MyDrive/svi_metadata/image_metadata.csv\")\n",
        "\n",
        "# Convert to GeoDataFrame\n",
        "gdf_image = gpd.GeoDataFrame(\n",
        "    df_image,\n",
        "    geometry=gpd.points_from_xy(df_image.lon, df_image.lat),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# Export to GeoJSON\n",
        "gdf_image.to_file(\"/content/drive/MyDrive/svi_metadata/image_metadata.geojson\", driver=\"GeoJSON\")\n",
        "print(\"‚úÖ image_metadata.geojson saved\")\n"
      ],
      "metadata": {
        "id": "o7u-9sGPklnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import h3\n",
        "from shapely.geometry import Polygon\n",
        "\n",
        "# Load image metadata\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/svi_metadata/image_metadata.csv\")\n",
        "\n",
        "# Compute H3 resolution 11 hex ID\n",
        "df['h3_11'] = df.apply(lambda row: h3.geo_to_h3(row['lat'], row['lon'], 11), axis=1)\n",
        "\n",
        "# Aggregate to each H3 cell\n",
        "df_grid = df.groupby('h3_11').agg({\n",
        "    'relative_angle': 'mean',\n",
        "    'speed_kmh': 'mean',\n",
        "    'hour': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Convert H3 cell to polygon geometry\n",
        "def h3_to_polygon(h):\n",
        "    try:\n",
        "        return Polygon(h3.h3_to_geo_boundary(h, geo_json=True))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "df_grid['geometry'] = df_grid['h3_11'].apply(h3_to_polygon)\n",
        "\n",
        "# Convert to GeoDataFrame\n",
        "gdf_grid = gpd.GeoDataFrame(df_grid, geometry='geometry', crs='EPSG:4326').dropna(subset=['geometry'])\n",
        "\n",
        "# Export to GeoJSON\n",
        "gdf_grid.to_file(\"/content/drive/MyDrive/svi_metadata/image_metadata_h3_11.geojson\", driver=\"GeoJSON\")\n",
        "\n",
        "print(\"‚úÖ Exported very small hex grid to image_metadata_h3_11.geojson\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LPDGqPZ3kvA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Summarize label_name counts\n",
        "label_summary = df_all['label_name'].value_counts().reset_index()\n",
        "label_summary.columns = ['label_name', 'count']\n",
        "\n",
        "# üìä Show table\n",
        "import pandas as pd\n",
        "import IPython.display as display\n",
        "display.display(label_summary)\n"
      ],
      "metadata": {
        "id": "t9pzxDzBrWho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "base_path = Path(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_svi\")  # replace with your path\n",
        "\n",
        "print(f\"Listing all folders/files under {base_path}:\")\n",
        "\n",
        "for p in base_path.iterdir():\n",
        "    print(p.name, \"Folder\" if p.is_dir() else \"File\")\n"
      ],
      "metadata": {
        "id": "1DVoikpbi0bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zensvi.cv import ClassifierPerception\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# ‚úÖ All supported perception indicators\n",
        "perception_indicators = [\n",
        "   # 'safer',\n",
        "  #  'more boring',\n",
        "  #  'wealthier',\n",
        " #   'livelier',\n",
        "  #  'more beautiful',\n",
        "    'more depressing'\n",
        "]\n",
        "\n",
        "# üìÇ Base path to your image batches\n",
        "base_path = Path(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_svi\")\n",
        "\n",
        "# === Loop over each indicator ===\n",
        "for indicator in perception_indicators:\n",
        "    print(f\"\\nüîé Starting indicator: {indicator}\")\n",
        "    classifier = ClassifierPerception(perception_study=indicator)\n",
        "\n",
        "    # Loop through each batch folder\n",
        "    for batch_folder in sorted(base_path.glob(\"batch_*\")):\n",
        "        print(f\"‚û°Ô∏è Classifying {batch_folder.name} | Indicator: {indicator}\")\n",
        "\n",
        "        # Output summary folder\n",
        "        out_path = batch_folder / f\"summaries_{indicator.replace(' ', '_')}\"\n",
        "        out_path.mkdir(exist_ok=True)\n",
        "\n",
        "        # === Create a folder for valid images ===\n",
        "        valid_folder = batch_folder / \"valid_images\"\n",
        "        if valid_folder.exists():\n",
        "            shutil.rmtree(valid_folder)\n",
        "        valid_folder.mkdir()\n",
        "\n",
        "        # === Filter and copy valid images ===\n",
        "        valid_count = 0\n",
        "        for image_path in batch_folder.glob(\"*.png\"):\n",
        "            try:\n",
        "                with Image.open(image_path) as img:\n",
        "                    img.verify()\n",
        "                shutil.copy(image_path, valid_folder / image_path.name)\n",
        "                valid_count += 1\n",
        "            except Exception:\n",
        "                print(f\"‚ö†Ô∏è Skipping corrupted image: {image_path.name}\")\n",
        "\n",
        "        if valid_count == 0:\n",
        "            print(f\"‚ùå No valid images in {batch_folder.name}, skipping classification.\")\n",
        "            continue\n",
        "\n",
        "        # === Run classification ===\n",
        "        try:\n",
        "            classifier.classify(\n",
        "                str(valid_folder),\n",
        "                dir_summary_output=str(out_path),\n",
        "                batch_size=5\n",
        "            )\n",
        "            print(f\"‚úÖ Done: {batch_folder.name} | {indicator}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Classification failed on {batch_folder.name} | {indicator}: {e}\")\n",
        "\n",
        "print(\"\\n‚úÖ Finished batch classification for all indicators.\")\n"
      ],
      "metadata": {
        "id": "eb8VBaoQ6MB0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# === Define Paths ===\n",
        "base_dir = Path(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_svi\")\n",
        "summary_folder_name = \"summaries_more_depressing\"  # e.g., 'summaries_safer', 'summaries_livelier'\n",
        "output_filename = f\"combined_{summary_folder_name}_results.csv\"\n",
        "\n",
        "# === Scan batch folders manually ===\n",
        "all_results = []\n",
        "for batch_folder in sorted(os.listdir(base_dir)):\n",
        "    batch_path = base_dir / batch_folder\n",
        "    summary_path = batch_path / summary_folder_name / \"results.csv\"\n",
        "\n",
        "    if summary_path.exists():\n",
        "        try:\n",
        "            df = pd.read_csv(summary_path)\n",
        "            df['batch'] = batch_folder  # Annotate with batch name\n",
        "            all_results.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to load {summary_path}: {e}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è No results.csv in {summary_path}\")\n",
        "\n",
        "# === Combine all data ===\n",
        "if all_results:\n",
        "    combined_df = pd.concat(all_results, ignore_index=True)\n",
        "    output_path = base_dir / output_filename\n",
        "    combined_df.to_csv(output_path, index=False)\n",
        "\n",
        "    print(f\"‚úÖ Combined shape: {combined_df.shape}\")\n",
        "    print(f\"üìÅ Saved to: {output_path}\")\n",
        "else:\n",
        "    print(\"üö´ No valid results found to combine.\")\n"
      ],
      "metadata": {
        "id": "IV70imjp9uXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Paths\n",
        "perception_path = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_svi/combined_summaries_more_depressing_results.csv\"\n",
        "panoids_path = \"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_pids_renamed.csv\"\n",
        "\n",
        "# Load data\n",
        "df_perception = pd.read_csv(perception_path)\n",
        "df_panoids = pd.read_csv(panoids_path)\n"
      ],
      "metadata": {
        "id": "GzhNCH2T-yyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = df_perception.merge(\n",
        "    df_panoids[['panoid', 'lat', 'lon']],\n",
        "    left_on='filename_key',\n",
        "    right_on='panoid',\n",
        "    how='inner'\n",
        ")\n",
        "print(f\"‚úÖ Merged shape: {df_merged.shape}\")\n"
      ],
      "metadata": {
        "id": "_QKK8_R8-08w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf = gpd.GeoDataFrame(\n",
        "    df_merged,\n",
        "    geometry=gpd.points_from_xy(df_merged['lon'], df_merged['lat']),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "gdf.to_file(\"/content/drive/MyDrive/zensvi_outputs/summaries_depressing_map.geojson\", driver=\"GeoJSON\")\n"
      ],
      "metadata": {
        "id": "n4A_shbU-1pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "image_paths = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/mly_svi/batch_*/**/*.png\", recursive=True)\n",
        "print(f\"üì∑ Total images on disk: {len(image_paths)}\")\n"
      ],
      "metadata": {
        "id": "NfMXQsekkKHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "segmented_paths = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/segments/*.png\", recursive=True)\n",
        "print(f\"üß† Segmented images found: {len(segmented_paths)}\")\n"
      ],
      "metadata": {
        "id": "jHzQhd09kQCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "img_paths = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/batch_*/**/*.png\", recursive=True)\n",
        "print(f\"üì∏ Total images available for segmentation: {len(img_paths)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "gzrSBCBIqCkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "seg_imgs = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/segments/*.png\", recursive=True)\n",
        "print(f\"üß† Actual segmented output images: {len(seg_imgs)}\")\n"
      ],
      "metadata": {
        "id": "WfK4PIJsmkTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "paths = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/summaries/pixel_ratios.csv\", recursive=True)\n",
        "\n",
        "nonempty = 0\n",
        "for p in paths:\n",
        "    try:\n",
        "        df = pd.read_csv(p)\n",
        "        if not df.empty:\n",
        "            nonempty += 1\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "print(f\"üìä Non-empty pixel_ratios.csv files: {nonempty} of {len(paths)}\")\n"
      ],
      "metadata": {
        "id": "oO4gmrTCmrdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Get a few summary files\n",
        "summary_files = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/summaries/*.json\", recursive=True)\n",
        "\n",
        "print(f\"üì¶ Found {len(summary_files)} summary files\")\n",
        "\n",
        "# Inspect first few\n",
        "for f in summary_files[:5]:\n",
        "    size_kb = os.path.getsize(f) / 1024\n",
        "    try:\n",
        "        with open(f, 'r') as infile:\n",
        "            data = json.load(infile)\n",
        "        print(f\"{f} ‚Äî ‚úÖ Valid JSON ({size_kb:.1f} KB)\")\n",
        "    except Exception as e:\n",
        "        print(f\"{f} ‚Äî ‚ùå Corrupt or unreadable: {e}\")\n"
      ],
      "metadata": {
        "id": "ME_tS93gk0vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Find a sample pixel_ratios.csv file\n",
        "csv_files = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/summaries/pixel_ratios.csv\", recursive=True)\n",
        "\n",
        "# Check if any files were found\n",
        "print(\"Found:\", len(csv_files))\n",
        "if len(csv_files) > 0:\n",
        "    df = pd.read_csv(csv_files[0])\n",
        "    print(\"Columns:\", df.columns.tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "_gf1WawReLcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Input/output paths\n",
        "summary_paths = glob.glob(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/**/summaries/pixel_ratios.csv\", recursive=True)\n",
        "\n",
        "for path in summary_paths:\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Pivot long to wide format\n",
        "    df_wide = df.pivot_table(\n",
        "        index='filename_key',\n",
        "        columns='label_name',\n",
        "        values='pixel_ratios',\n",
        "        aggfunc='mean'\n",
        "    ).reset_index()\n",
        "\n",
        "    # Overwrite the original or save as new\n",
        "    wide_path = path.replace(\"pixel_ratios.csv\", \"pixel_ratios_wide.csv\")\n",
        "    df_wide.to_csv(wide_path, index=False)\n",
        "    print(f\"‚úÖ Saved wide-format CSV: {wide_path}\")\n"
      ],
      "metadata": {
        "id": "yeDuWdfKhQ1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_wide = pd.read_csv(\"/content/drive/MyDrive/zensvi_outputs/from_shapefile/images/mly_svi/batch_1/summaries/pixel_ratios_wide.csv\")\n",
        "print(df_wide.describe())\n"
      ],
      "metadata": {
        "id": "FyZck19IjDBl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
